{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 콜백을 사용하여 모델 훈련 과정 제어하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 콜백은 모델의 fit() 메서드가 호출될 떄 전달되는 객체(특정 메서드를 구현한 클래스 객체)입니다. 훈련하는 동안 모델을 여러 지점에서 호출합니다. 콜백은 모델의 상태와 성능에 대한 모든 정보에 접근하고 훈련 중지, 모델 저장, 가중치 적재, 모델 상태 변경을 처리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 콜백 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 체크포인트 저장: 훈련하는 동안 어떤 지점에서 모델 현재 가중치를 저장한다.\n",
    "- 조기 종료: 검증 손실이 더 이상 향상되지 않을 때 훈련을 중지한다.\n",
    "- 훈련하는 동안 하이퍼파라미터 값을 동적으로 조정한다.\n",
    "- 훈련과 검증 지표를 로그에 기록하거나 모델이 학습한 표현이 업데이트 될 때마다 시각화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelCheckpoint와 EarlyStopping 콜백"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EarlyStopping 콜백: 정해진 에포크 동안 모니터링 지표가 향상되지 않음\n",
    "- ModelCheckpoint: 훈련 동안 모델을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    keras.callbacks.EarlyStopping( # 성능 향상이 멈추면 훈련을 중지한다.\n",
    "        monitor='val_acc',\n",
    "        patience=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint( # 에폭마다 현재 가중치를 젖아한다.\n",
    "        filepath='my_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4587018ffd9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# fit, fit_generator에 callback을 부를 수 있다.\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "# model.fit(x, y, epochs=10, batch_size=32, callbacks=callback_list, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateau 콜백"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 손실이 향상되지 않을 떄 학습률을 작게 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1, # 콜백이 호출될 떄 학습률을 10배로 줄인다.\n",
    "        patience=10\n",
    "    )\n",
    "]\n",
    "\n",
    "# model.fit(x, y, epochs=10, batch_size=32, callbacks=callbacks_list, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자신만의 콜백 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on_epoch_begin: 각 에포크가 시작할 때 호출한다.\n",
    "- on_epoch_end: 각 에포크가 끝날 떄 호출한다.\n",
    "\n",
    "- on_batch_begin: 각 배치가 시작되기 전에 호출한다.\n",
    "- on_batch_end: 각 배치가 끝난 후에 호출한다.\n",
    "\n",
    "- on_train_begin: 훈련이 시작될 때 호출한다.\n",
    "- on_train_end: 훈련이 끝날 때 호출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs) # 각 층의 활성화 출력을 반환하는 Model 객체\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError(\"Requires validation data.\")\n",
    "            \n",
    "        validation_sample = self.validation_data[0][0:1]\n",
    "        activations = self.activations_model.perdict(validation_sample)\n",
    "        f = open('activations_at_epoch' + str(epoch) + '.npz', 'wb')\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 텐서보드: 텐서플로의 시각화 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서보드의 핵심 목적은 훈련 모델의 내부에서 일어나는 모든 것을 시각적으로 모니터링할 수 있도록 돕는 것이다. 모델의 최종 손실 외에 더 많은 정보를 모니터링하면 모델 작동에 대한 명확한 그림을 그릴 수 잇습니다. 결국 모델을 더 빠르게 개선할 수 있습니다. 텐서보드는 여러가지 멋진 기능을 제공합니다. 모두 브라우저에서 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "max_len = 500\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data('imdb.npz', num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,315,937\n",
      "Trainable params: 1,315,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.5695 - acc: 0.7108 - val_loss: 0.4169 - val_acc: 0.8404\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.3752 - acc: 0.8148 - val_loss: 0.5406 - val_acc: 0.7622\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.2806 - acc: 0.7295 - val_loss: 0.5016 - val_acc: 0.7372\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.2028 - acc: 0.6701 - val_loss: 0.8359 - val_acc: 0.5434\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1562 - acc: 0.5789 - val_loss: 0.7343 - val_acc: 0.5138\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1227 - acc: 0.4583 - val_loss: 0.8403 - val_acc: 0.4276\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.1056 - acc: 0.3709 - val_loss: 0.9710 - val_acc: 0.3562\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.0997 - acc: 0.2815 - val_loss: 1.0413 - val_acc: 0.3134\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.0941 - acc: 0.2053 - val_loss: 1.1078 - val_acc: 0.2766\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.0938 - acc: 0.1683 - val_loss: 1.1001 - val_acc: 0.2612\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.0895 - acc: 0.1447 - val_loss: 1.1921 - val_acc: 0.2290\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.0909 - acc: 0.1072 - val_loss: 1.1989 - val_acc: 0.2244\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.0919 - acc: 0.0954 - val_loss: 1.2757 - val_acc: 0.2038\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.0867 - acc: 0.0810 - val_loss: 1.3028 - val_acc: 0.2024\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0841 - acc: 0.0779 - val_loss: 1.3252 - val_acc: 0.1880\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.0865 - acc: 0.0670 - val_loss: 1.2837 - val_acc: 0.1818\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.0821 - acc: 0.0591 - val_loss: 1.3274 - val_acc: 0.1758\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.0814 - acc: 0.0538 - val_loss: 1.7222 - val_acc: 0.1640\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.0822 - acc: 0.0501 - val_loss: 1.4663 - val_acc: 0.1606\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.0837 - acc: 0.0452 - val_loss: 1.3151 - val_acc: 0.1614\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='log_dir',\n",
    "        histogram_freq=1, # 1 에포크마다 활성화 출력 히스토그램 기록\n",
    "        embeddings_freq=1 # 1 에포크마다 임베딩 데이터 기록\n",
    "    )\n",
    "]\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 정리\n",
    "\n",
    "- 케라스 콜백은 훈련하는 동안 모델을 모니터링하고 모델 상태를 바탕으로 자동으로 작업을 수행하는 손쉬운 방법입니다.\n",
    "- 텐서플로를 사용하면 텐서보드를 이용하여 모델 상황을 브라우저에서 시각화할 수 있습니다. 케라스 모델에서는 Tensorboard 콜백을 통해 사용합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
